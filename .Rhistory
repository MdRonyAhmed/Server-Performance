View(training_dataset)
test_applications = applications %>% mean((
group_by(Image_Height) %>%
slice(-(1:10))))
test_applications = applications %>%
group_by(Image_Height) %>%
slice(-(1:10))
View(test_applications)
test_applications = applications %>%
group_by(Image_Height) %>%
slice(-(1:10))
View(test_applications)
training_dataset = mean(applications %>%
group_by(Image_Height) %>%
slice_head(n=10))
training_dataset = applications %>%
group_by(Image_Height) %>%
slice_head(n=10)
View(training_dataset)
collumn_mean = colMeans(training_dataset %>%
group_by(Image_Height) %>%
slice_head(n=10))
collumn_mean = colMeans(training_dataset %>%
group_by(Image_Height) %>%
slice_head(n=10))
collumn_mean = colMeans(training_dataset %>%
group_by(Image_Height) %>%
slice_head(n=10))
print(collumn_mean)
# load reciured library
library(tidyverse)
# read the data
applications = read_csv("Amplification.csv")
# take the first 10 obserbation of each image size
training_dataset = applications %>%
group_by(Image_Height) %>%
slice_head(n=10)
applications.summary
library(tidyverse)
# read the data
applications = read_csv("Amplification.csv")
# take the first 10 obserbation of each image size
training_dataset = applications %>%
group_by(Image_Height) %>%
slice_head(n=10)
Applications.summary
# load reciured library
library(tidyverse)
# read the data
applications = read_csv("Amplification.csv")
# take the first 10 obserbation of each image size
training_dataset = applications %>%
group_by(Image_Height) %>%
slice_head(n=10)
applications.summary()
# load reciured library
library(tidyverse)
# read the data
applications = read_csv("Amplification.csv")
# take the first 10 obserbation of each image size
training_dataset = applications %>%
group_by(Image_Height) %>%
slice_head(n=10)
applications.summary
# load reciured library
library(tidyverse)
# read the data
applications = read_csv("Amplification.csv")
# take the first 10 obserbation of each image size
training_dataset = applications %>%
group_by(Image_Height) %>%
slice_head(n=10)
applications.summary
collumn_mean <- colMeans(training_dataset %>%
group_by(Image_Height) %>%
slice_head(n=10))
print(collumn_mean)
collumn_mean <- colMeans(training_dataset)
collumn_mean <- colMeans(training_dataset)
print(collumn_mean)
Application.summary()
application.summary()
Application.summary()
applications.summary()
read_data.summary()
aplications.summary
aplications.summary()
applications.summary()
applications.summary
applications = read_csv("Amplification.csv")
print(applications.summary())
library(tidyverse)
# read the data
applications = read_csv("Amplification.csv")
# take the first 10 obserbation of each image size
training_dataset = applications %>%
group_by(Image_Height) %>%
slice_head(n=10)
Application.summary()
library(tidyverse)
# read the data
applications = read_csv("Amplification.csv")
# take the first 10 obserbation of each image size
training_dataset = applications %>%
group_by(Image_Height) %>%
slice_head(n=10)
Application.summary()
library(tidyverse)
# read the data
applications = read_csv("Amplification.csv")
# take the first 10 obserbation of each image size
training_dataset = applications %>%
group_by(Image_Height) %>%
slice_head(n=10)
summary(slice_head(10))
library(tidyverse)
# read the data
applications = read_csv("Amplification.csv")
# take the first 10 obserbation of each image size
training_dataset = applications %>%
group_by(Image_Height) %>%
slice_head(n=10)
summary(slice_head(10))
test_applications = applications %>% colMeans(
group_by(Image_Height) %>%
slice(-(1:10)))
View(data)
test_dataset = applications - training_dataset
#collumn_mean <- colMeans(training_dataset)
#print(collumn_mean)
# load reciured library
library(tidyverse)
# read the data
applications = read_csv("Amplification.csv")
# take the first 10 obserbation of each image size
training_dataset = applications %>%
group_by(Image_Height) %>%
summary(slice_head(n=10))
#aplications.summary
test_dataset = applications - training_dataset
print(test_dataset)
test_applications = applications %>%
group_by(Image_Height) %>%
slice(-(1:10))
training_dataset <- applications %>%
group_by(Image_Height) %>%
summary(slice_head(n=10))
training_dataset <- applications %>%
group_by(Image_Height) %>%
summary(slice_head(n=10))
print(training_dataset)
training_dataset = applications %>%
group_by(Image_Height) %>%
summary(slice_head(n=10))
training_dataset = applications %>%
group_by(Image_Height) %>%
summary(slice_head(n=10))
print(training_dataset)
length2 <- function (x=applications, na.rm=FALSE) {
if (na.rm) sum(!is.na(x))
else       length(x)
}
View(length2)
length2(applications)
data <- length2(applications)
training_dataset = applications %>%
group_by(Image_Height) %>%
summary(slice_head(n=10))
print(training_dataset)
# load reciured library
library(tidyverse)
# read the data
applications = read_csv("Amplification.csv")
# take the first 10 obserbation of each image size
training_dataset = applications %>%
group_by(Image_Height) %>%
summary(slice_head(n=10))
print(training_dataset)
#aplications.summary
test_dataset = applications - training_dataset
print(test_dataset)
test_applications = applications %>%
group_by(Image_Height) %>%
slice(-(1:10))
#collumn_mean <- colMeans(training_dataset)
#print(collumn_mean)
#Regression Analysis
#library(tidyverse)
#library(ggpubr)
#theme_set(theme_pubr())
#length2 <- function (x=applications, na.rm=FALSE) {
#  if (na.rm) sum(!is.na(x))
#  else       length(x)
#}
# load reciured library
library(tidyverse)
# read the data
applications = read_csv("Amplification.csv")
# take the first 10 obserbation of each image size
training_dataset = applications %>%
group_by(Image_Height) %>%
summary(slice_head(n=10))
print(training_dataset)
#aplications.summary
test_dataset = applications - training_dataset
print(test_dataset)
test_applications = applications %>%
group_by(Image_Height) %>%
slice(-(1:10))
#collumn_mean <- colMeans(training_dataset)
#print(collumn_mean)
#Regression Analysis
#library(tidyverse)
#library(ggpubr)
#theme_set(theme_pubr())
#length2 <- function (x=applications, na.rm=FALSE) {
#  if (na.rm) sum(!is.na(x))
#  else       length(x)
#}
View(test_applications)
View(test_applications)
regres = lm(canny_time ~ Canny_flops + Canny_bytes, training_dataset)
library(tidyverse)
# read the data
applications = read_csv("Amplification.csv")
# take the first 10 obserbation of each image size
training_dataset = applications %>%
group_by(Image_Height) %>%
slice_head(n=10)
avg_dataset = applications %>%
group_by(Image_Height) %>%
summary(slice_head(n=10))
test_dataset = applications %>%
group_by(Image_Height) %>%
slice(-(1:10))
#Regression Analysis
regres = lm(canny_time ~ Canny_flops + Canny_bytes, training_dataset)
View(regres)
summary(regressor)
summary(regres)
exe_timePredict = predict(regres, newdata = test_dataset)
print(data.frame(exe_timePredict = test_dataset$exe_timePredict, exe_timePredict = exe_timePredict))
print(data.frame(Time = test_dataset$Time, prediction = exe_timePredict))
print(data.frame(canny_time = test_dataset$canny_time, prediction = exe_timePredict))
library(ggplot2)
ggplot() +
geom_point(aes(x = training_dataset$Canny_flops + Canny_bytes, y = training_dataset$canny_time), colour = 'green') +
geom_point(aes(x = test_dataset$Canny_flops + Canny_bytes, y = test_dataset$canny_time), colour = 'red') +
geom_line(aes(x = training_set$Canny_flops + Canny_bytes, y = predict(regres, newdata = training_dataset)), colour = 'blue') +
ggtitle('Canny_time vs Canny_flops (Green: Training Set, Red: Test Set)') +
xlab('Canny_flops') +
ylab('Canny_time')
View(training_dataset)
library(ggplot2)
ggplot() +
geom_point(aes(x = training_dataset$Canny_flops + Canny_bytes, y = training_dataset$canny_time), colour = 'green') +
geom_point(aes(x = test_dataset$Canny_flops + Canny_bytes, y = test_dataset$canny_time), colour = 'red') +
geom_line(aes(x = training_set$Canny_flops + Canny_bytes, y = predict(regres, newdata = training_dataset)), colour = 'blue') +
ggtitle('Canny_time vs Canny_flops (Green: Training Set, Red: Test Set)') +
xlab('Canny_flops') +
ylab('Canny_time')
library(ggplot2)
ggplot() +
geom_point(aes(x = training_dataset$Canny_flops , y = training_dataset$canny_time), colour = 'green') +
geom_point(aes(x = test_dataset$Canny_flops , y = test_dataset$canny_time), colour = 'red') +
geom_line(aes(x = training_set$Canny_flops , y = predict(regres, newdata = training_dataset)), colour = 'blue') +
ggtitle('Canny_time vs Canny_flops (Green: Training Set, Red: Test Set)') +
xlab('Canny_flops') +
ylab('Canny_time')
ggplot() +
geom_point(aes(x = training_dataset$Canny_flops , y = training_dataset$canny_time), colour = 'green') +
geom_point(aes(x = test_dataset$Canny_flops , y = test_dataset$canny_time), colour = 'red') +
geom_line(aes(x = training_dataset$Canny_flops , y = predict(regres, newdata = training_dataset)), colour = 'blue') +
ggtitle('Canny_time vs Canny_flops (Green: Training Set, Red: Test Set)') +
xlab('Canny_flops') +
ylab('Canny_time')
ggplot() +
geom_point(aes(x = training_dataset$Canny_flops + Canny_bytes, y = training_dataset$canny_time), colour = 'green') +
geom_point(aes(x = test_dataset$Canny_flops + Canny_bytes, y = test_dataset$canny_time), colour = 'red') +
geom_line(aes(x = training_set$Canny_flops + Canny_bytes, y = predict(regres, newdata = training_dataset)), colour = 'blue') +
ggtitle('Canny_time vs Canny_flops (Green: Training Set, Red: Test Set)') +
xlab('Canny_flops') +
ylab('Canny_time')
ggplot() +
geom_point(aes(x = training_dataset$Canny_flops + training_dataset$Canny_bytes, y = training_dataset$canny_time), colour = 'green') +
geom_point(aes(x = test_dataset$Canny_flops + training_dataset$Canny_bytes, y = test_dataset$canny_time), colour = 'red') +
geom_line(aes(x = training_set$Canny_flops + training_dataset$Canny_bytes, y = predict(regres, newdata = training_dataset)), colour = 'blue') +
ggtitle('Canny_time vs Canny_flops (Green: Training Set, Red: Test Set)') +
xlab('Canny_flops') +
ylab('Canny_time')
library(ggplot2)
ggplot() +
geom_point(aes(x = training_dataset$Canny_flops + training_dataset$Canny_bytes, y = training_dataset$canny_time), colour = 'green') +
geom_point(aes(x = test_dataset$Canny_flops + training_dataset$Canny_bytes, y = test_dataset$canny_time), colour = 'red') +
geom_line(aes(x = training_dataset$Canny_flops + training_dataset$Canny_bytes, y = predict(regres, newdata = training_dataset)), colour = 'blue') +
ggtitle('Canny_time vs Canny_flops (Green: Training Set, Red: Test Set)') +
xlab('Canny_flops') +
ylab('Canny_time')
ggplot() +
geom_point(aes(x = training_dataset$Canny_flops + training_dataset$Canny_bytes, y = training_dataset$canny_time), colour = 'green') +
geom_point(aes(x = test_dataset$Canny_flops + training_dataset$Canny_bytes, y = test_dataset$canny_time), colour = 'red') +
geom_line(aes(x = training_dataset$Canny_flops + training_dataset$Canny_bytes, y = predict(regres, newdata = training_dataset)), colour = 'blue') +
ggtitle('Canny_time vs Canny_flops & Canny_bytes (Green: Training Set, Red: Test Set)') +
xlab('Canny_flops & Canny_bytes') +
ylab('Canny_time')
# load reciured library
library(tidyverse)
# read the data
applications = read_csv("Amplification.csv")
# take the first 10 obserbation of each image size
training_dataset = applications %>%
group_by(Image_Height) %>%
slice_head(n=10)
avg_dataset = applications %>%
group_by(Image_Height) %>%
summary(slice_head(n=10))
test_dataset = applications %>%
group_by(Image_Height) %>%
slice(-(1:10))
#Regression Analysis
regres = lm(canny_time ~ Canny_flops + Canny_bytes, training_dataset)
summary(regres)
exe_timePredict = predict(regres, newdata = test_dataset)
print(data.frame(canny_time = test_dataset$canny_time, prediction_time = exe_timePredict))
#Graph View
library(ggplot2)
ggplot() +
geom_point(aes(x = training_dataset$Canny_flops + training_dataset$Canny_bytes, y = training_dataset$canny_time), colour = 'green') +
geom_point(aes(x = test_dataset$Canny_flops + training_dataset$Canny_bytes, y = test_dataset$canny_time), colour = 'red') +
geom_line(aes(x = training_dataset$Canny_flops + training_dataset$Canny_bytes, y = predict(regres, newdata = training_dataset)), colour = 'blue') +
ggtitle('Canny_time vs Canny_flops & Canny_bytes (Green: Training Set, Red: Test Set)') +
xlab('Canny_flops & Canny_bytes') +
ylab('Canny_time')
cor.test(canny_time, Canny_flops + Canny_bytes)
cor.test(canny_time, Canny_flops)
# load reciured library
library(tidyverse)
# read the data
applications = read_csv("Amplification.csv")
# take the first 10 obserbation of each image size
training_dataset = applications %>%
group_by(Image_Height) %>%
slice_head(n=10)
avg_dataset = applications %>%
group_by(Image_Height) %>%
summary(slice_head(n=10))
test_dataset = applications %>%
group_by(Image_Height) %>%
slice(-(1:10))
#Regression Analysis
regres = lm(canny_time ~ Canny_flops + Canny_bytes, training_dataset)
cor.test(canny_time, Canny_flops)
cor.test(training_dataset$canny_time, training_dataset$Canny_flops)
cor.test(training_dataset$canny_time, training_dataset$Canny_flops + training_dataset$Canny_bytes )
r <- cor.test(training_dataset$canny_time, training_dataset$Canny_flops + training_dataset$Canny_bytes )
r <- cor.test(training_dataset$canny_time, training_dataset$Canny_flops + training_dataset$Canny_bytes ) %>% .$conf.int
print(data.frame(canny_time = test_dataset$canny_time, prediction_time = exe_timePredict))
applications %>% .[2,12,] %>%
group_by(Image_Height) %>%
slice_head(n=10)
applications %>% .[2,12,] %>%
group_by(Image_Height) %>%
slice_head(n=10)
applications %>%
group_by(Image_Height) %>% .[2,12,] %>%
slice_head(n=10)
applications %>% .[,2:12] %>%
group_by(Image_Height) %>%
slice_head(n=10)
avg_dataset = applications %>% .[,2:12] %>%
group_by(Image_Height) %>%
slice_head(n=10) %>% summarise_each(funs = mean)
avg_dataset = applications %>% .[,2:12] %>%
group_by(Image_Height) %>%
slice_head(n=10) %>% across(funs = mean)
avg_dataset = applications %>% .[,2:12] %>%
group_by(Image_Height) %>%
slice_head(n=10) %>% summarise_all(funs = mean)
avg_dataset = applications %>% .[,2:12] %>%
group_by(Image_Height) %>%
slice_head(n=10) %>% summarise_all(.funs = mean)
View(avg_dataset)
Summary (applications)
library(tidyverse)
# read the data
applications = read_csv("Amplification.csv")
# take the first 10 obserbation of each image size
training_dataset = applications %>%
group_by(Image_Height) %>%
slice_head(n=10)
avg_dataset = applications %>% .[,2:12] %>%
group_by(Image_Height) %>%
slice_head(n=10) %>% summarise_all(.funs = mean)
test_dataset = applications %>%
group_by(Image_Height) %>%
slice(-(1:10))
#Regression Analysis
regres = lm(canny_time ~ Canny_flops + Canny_bytes, training_dataset)
r <- cor.test(training_dataset$canny_time, training_dataset$Canny_flops + training_dataset$Canny_bytes ) %>% .$conf.int
exe_timePredict = predict(regres, newdata = test_dataset)
print(data.frame(canny_time = test_dataset$canny_time, prediction_time = exe_timePredict))
Summary (applications)
summary (applications)
View(avg_dataset)
View(avg_dataset)
View(avg_dataset)
write.table (avg_dataset)
write.table (avg_dataset,file = "data.csv",
sep = "\t", row.names = F)
write.table (avg_dataset,file = "Average_dataset.csv",
sep = "\t", row.names = F)
library(WriteXLS)
WriteXLS(data, ExcelFileName = "data.xlsx",
SheetNames = "my data",
AdjWidth = T,
BoldHeaderRow = T)
install.packages('WriteXLS')
library(WriteXLS)
WriteXLS(avg_dataset, ExcelFileName = "Average_dataset.xlsx",
SheetNames = "my data",
AdjWidth = T,
BoldHeaderRow = T)
library(WriteXLS)
WriteXLS(avg_dataset, ExcelFileName = "Average_dataset.xlsx",
SheetNames = "my data",
AdjWidth = T,
BoldHeaderRow = T)
summary = applications %>%
group_by(Image_Height)  %>%
select( dependent_var_1,  dependent_var_2, dependent_var_1)    %>%  summary ()
summary = applications %>%
group_by(Image_Height)  %>%
select( canny_time,  vertical_time, horizontal_time)    %>%  summary ()
applications %>%
group_by(Image_Height)  %>%
select( canny_time,  vertical_time, horizontal_time)    %>%  summary ()
summary = applications %>%
group_by(Image_Height)  %>%
select( canny_time,  vertical_time, horizontal_time)    %>%  summarise_all()
summary = applications %>%
group_by(Image_Height)  %>%
select( canny_time,  vertical_time, horizontal_time)    %>%  summary.table ()
applications %>%
group_by(Image_Height)  %>%
select( canny_time,  vertical_time, horizontal_time)    %>%  summary()
print(summary.data.frame())
print(summary)
View(applications)
aggregate(canny_time,vertical_time,horizontal_time , data= warpbreaks, mean)
aggregate(applications$canny_time,applications$vertical_time,applications$horizontal_time , data= warpbreaks, mean)
aggregate(applications$canny_time~applications$horizontal_time , data= warpbreaks, mean)
library(psych)
describe(warpbreaks)
aggregate(applications$canny_time~applications$horizontal_time , data= warpbreaks, mean)
library(psych)
describe(warpbreaks)
aggregate(applications$canny_time~applications$horizontal_time , data= warpbreaks, mean)
install.packages('psych')
library(psych)
describe(warpbreaks)
aggregate(applications$canny_time~applications$horizontal_time , data= warpbreaks, mean)
library(psych)
describe(applications)
library(psych)
describe(applications)
aggregate(applications$canny_time~applications$horizontal_time , data= applications, mean)
summary = applications %>%
group_by(Image_Height)  %>%
select( canny_time,  vertical_time, horizontal_time)    %>%  describe()
View(summary)
summary = applications %>%
group_by(Image_Height)  %>% (
select( canny_time,  vertical_time, horizontal_time)%>%  describe())
summary = applications %>%
group_by(Image_Height)  %>% (
select( applications$canny_time,  applications$vertical_time, applications$horizontal_time)%>%  describe())
summary = applications %>%
group_by(Image_Height)  %>% (applications %>%
select( canny_time,  vertical_time, horizontal_time)%>%  describe())
View(summary)
summary(applications)
summary(regrestion_model)
regrestion_model = lm(canny_time ~ Canny_flops + Canny_bytes, training_dataset)
summary(regrestion_model)
regrestion_model = lm(canny_time ~ Canny_flops + Canny_bytes)
summary(regrestion_model)
regrestion_model = lm(canny_time ~ Canny_flops + Canny_bytes, training_dataset)
#get a summary of the model
summary(regrestion_model)
regrestion_model = lm(canny_time ~ Canny_flops + Canny_bytes, training_dataset).alias()
#get a summary of the model
summary(regrestion_model)
regrestion_model = lm(canny_time ~ Canny_flops + Canny_bytes, training_dataset).alias()
regrestion_model = lm(canny_time ~ Canny_flops + Canny_bytes, cor(training_dataset))
regrestion_model = alias(lm(canny_time ~ Canny_flops + Canny_bytes, training_dataset))
regrestion_model = alias(lm(canny_time ~ Canny_flops + Canny_bytes, training_dataset))
#get a summary of the model
summary(regrestion_model)
regrestion_model = alias.formual(canny_time ~ Canny_flops + Canny_bytes, training_dataset)
install.packages(alias)
"aliases2entrez"
regrestion_model = lm(canny_time ~ Canny_flops + Canny_bytes, training_dataset)
alias(regrestion_model)
regrestion_model = lm(canny_time ~ Canny_flops + Canny_bytes, training_dataset)
alias(regrestion_model)
#get a summary of the model
summary(regrestion_model)
regrestion_model = lm(canny_time ~ Canny_flops + Canny_bytes, training_dataset)
reg = alias(regrestion_model)
#get a summary of the model
summary(reg)
View(reg)
